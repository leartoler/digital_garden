---
{"dg-publish":true,"permalink":"/clippings/el-deep-learning-en-la-era-del-desfase-prometeico-ii/","title":"El deep learning en la era del desfase prometeico (II)","tags":["clippings"]}
---

---

[![](https://vonneumannmachine.wordpress.com/wp-content/uploads/2025/08/chatgpt-image-5-ago-2025-09_26_21.png)](https://vonneumannmachine.wordpress.com/?attachment_id=6943)

Anders subraya otra idea interesante: **la desconexión directa con las consecuencias de nuestras creaciones tecnológicas**. Si yo soy un técnico de la General Atomics, y en California ensamblo piezas de un dron de combate Mk-1 Predator, nunca veré al producto de mi trabajo lanzar misiles sobre guerrilleros hutíes en Yemen. Es muy probable que no tenga ni idea ni dónde ni contra quién va a usarse. ==Esa distancia produce indiferencia moral.== Si ni conozco, ni siquiera veo ni tengo casi noticia, de las víctimas de los misiles de mi dron, no me siento nada responsable de su suerte. Cuando las consecuencias de una acción ocurren en un lugar lejano y poco definido, cuanto menos concreto y más abstracto sea, menos me sentiré responsable de ello. Y es que estamos programados para que nos importen los que están cerca, los nuestros, los que se parecen a nosotros; y al contrario, a sospechar del raro, del diferente, del extranjero. En mis clases suelo hacerles a mis alumnos esta pregunta: **¿A quién salvarías antes de ser asesinado? ¿A tu perro o a mil personas en Sudán del Sur?** La respuesta es siempre casi unánime: a la mascota. Esto nos lleva a una compleja diatriba: ¿cómo conseguimos entonces tener un comportamiento ético con personas que no nos importan? ¿Cómo vamos a ayudar a la gente de Sudán del Sur si nos importan mucho menos que nuestro perro? Mi solución es que hay que ser más kantianos: ayudamos a la gente de Sudán del Sur no porque nos importe en absoluto, sino porque *debemos* hacerlo. Hay que hacer lo correcto con independencia de lo que nos haga sentir.

Sin embargo, siguiendo la lógica de Anders, el desfase prometeico de la tecnología contemporánea favorece esta indiferencia moral y emocional. Si eres un neandertal y fabricas un bifaz que usas para matar a otro, recibes todo el impacto moral de tu acción: no hay desconexión entre fabricación y uso de la herramienta, tú mismo ejecutas la acción y contemplas el rostro de tu víctima mientras muere (recordemos «la mirada del otro» de [Emmanuel Lévinas](https://es.wikipedia.org/wiki/Emmanuel_L%C3%A9vinas)). Has sido plenamente consciente de todo el daño causado por tu acción. Por el contrario, el técnico del Mk-1 Predator termina la jornada laboral y se va muy feliz con su familia a cenar unos tacos de pescado y unos burritos californianos. Es más difícil ser kantiano en la distancia, en la desinformación, en el olvido.

Otro concepto interesante de Anders ligado al desfase prometeico es el de la «vergüenza prometeica»: **el sentimiento que siente el hombre al verse superado por su creación**. Es lo que sintió Kasparov al ser derrotado por Deep Blue, o Le Sedol al perder contra AlphaGo. Si las máquinas nos superan, ¿qué nos quedará por hacer? El ser humano quedará obsoleto, expulsado de su protagonismo como sujeto de la historia ¿Por qué pintar un cuadro si una IA lo puede hacer infinitamente más rápido y mejor? ¿Por qué escribir una poesía si una IA puede generar miles en lo que tardas en coger el lápiz? ¿Cómo se enfrentará el orgulloso ser humano a esa vergüenza, a esa inferioridad? ¿La aceptará sin más y se dedicará al ocio y al bienestar que la IA podrá otorgarle? ¿O se enfrentará a su creación en un brote ludita? No obstante, aquí de nuevo estoy en cierto desacuerdo con Anders. En primer lugar, creo que el momento en el que las máquinas nos superen y nos hagan sentir esa vergüenza aún no ha llegado, y está mucho más lejos de llegar de lo que piensan muchos (No sé el lector, pero yo no me siento nada inferior a ChatGPT). Y en segundo, creo más en que la IA va a ir avanzando mucho más como herramienta que como sustituto. El ser humano no va a quedar obsoleto tan aprisa. Y, en cualquier caso, creo que las consecuencias no serían tan graves. Un automóvil corre mucho más rápido que Usain Bolt y eso no ha quitado un ápice del reconocimiento por los logros del atleta; tenemos grúas capaces de levantar miles de toneladas y eso no hizo que no nos quedásemos boquiabiertos cuando Hafþór Júlíus Björnsson batió el récord de levantamiento de peso muerto este mismo año, con 505 kilogramos; en ajedrez, las máquinas nos machacan inmisericordemente desde hace muchas décadas y eso no quita nada de la admiración que sentimos hacia Magnus Carlsen. **Son muchísimos los ejemplos en los que las máquinas lo hacen mejor que nosotros y las consecuencias no han sido emocionalmente tan drásticas como supone Anders**. Yo, la verdad, uso la calculadora de mi móvil para dividir la cuenta del restaurante, *sin sentir demasiada vergüenza prometeica* porque su capacidad de cálculo sea muy superior a la mía.

Bien, ¿y cuál es la solución que propone Anders ante este colapso moral? Algo bastante obvio: una **ética de la anticipación**. Hay que recuperar o reforzar nuestra capacidad de imaginar las consecuencias de nuestras producciones tecnológicas. No puede ser esperar al horror para tomar medidas después: hay que anticiparse. Esta tesis me recuerda a, probablemente, la mejor idea que ha dado un pensador español a la historia de la filosofía en los últimos tiempos: el concepto de [eficiencia tecnológica de Miguel Ángel Quintanilla](https://vonneumannmachine.wordpress.com/2015/11/08/eficiencia-tecnologica/). Un artefacto es eficiente sí, y solo sí, utiliza las medios más económicos para llegar a sus objetivos, *y nada más que a sus objetivos*. Dicho en otras palabras, para **construir una máquina eficiente debemos ser capaces de predecir todos los efectos no deseados inicialmente que pueda producir**. El reto: es sumamente difícil, si no imposible, predecir todos los efectos secundarios que tendrá una tecnología, más cuando evoluciona en el tiempo y en un entorno cambiante. No obstante, que sea complicado no quiere decir que no sea lo que hay que hacer; más viendo que hoy se lanzan artefactos al mercado sin el más mínimo estudio de impacto. Pensemos, muy seriamente, en los LLMs: cajas negras lanzadas al gran público… ¡Y ahora con funciones de agente!

Anders sostiene que hay que deshacerse de la funesta «Si algo puede hacerse, debe hacerse». Hay que rehumanizar la tecnología y **devolver la centralidad a la ética en las decisiones tecnológicas**. Hay que reforzar el papel de la política y de la deliberación democrática en la toma de decisiones de programas de desarrollo tecnológico que tienen consecuencias en las vidas de todos. Volvemos a recordar el gran problema que supone que media docena de empresas controlen la IA mundial, muy por encima de cualquier poder institucional.

