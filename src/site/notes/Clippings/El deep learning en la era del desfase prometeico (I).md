---
{"dg-publish":true,"permalink":"/clippings/el-deep-learning-en-la-era-del-desfase-prometeico-i/","title":"El deep learning en la era del desfase prometeico (I)","tags":["clippings"]}
---

---

[![](https://vonneumannmachine.wordpress.com/wp-content/uploads/2025/07/anders-y-la-ia.png)](https://vonneumannmachine.wordpress.com/?attachment_id=6927)

Voy a hacer al menos dos entradas sobre algunas ideas de la filosofía de la tecnología de Günther Anders, y voy a utilizarla como prisma para analizar algunos aspectos de la IA, que para eso valen los filósofos, para usarlos como instrumentos de observación del presente.

[Günther Anders](https://es.wikipedia.org/wiki/G%C3%BCnther_Anders) fue un filósofo polaco muy preocupado por la destrucción del mundo en los tiempos de la Guerra Fría, fue un tenaz pacifista y activista contra el desarrollo de bombas atómicas. Mantuvo una correspondencia con el norteamericano Claude Eatherly (piloto del avión de reconocimiento climático que seleccionó el objetivo al Enola Gay en el lanzamiento de la bomba sobre Hiroshima) que publicó en una obra titulada *Burning conscience* de 1961, lo que le valió a Anders ser considerado un comunista y una persona non grata en Estados Unidos. Y es que Eatherly sentía una culpabilidad tan grande por su colaboración en Hiroshima que se dedicó a cometer delitos para que lo ingresaran en prisión y así expiar de algún modo su culpa. Esa actitud le valió pasar buena parte de su vida entre la prisión y el manicomio para veteranos de Waco, y a ser considerado una figura incómoda, como todo pacifista, para el clásico belicismo institucional yankee. Hoy lo tacharían de woke.

Anders publicó su obra más importante, *La obsolescencia del hombre*, en dos tomos con más de veinte años de distancia el uno del otro: 1956 y 1980. En ella desarrolla una interesante idea: *el desfase prometeico*. Podría resumirse en que vivimos en una época en la que **nuestra capacidad de producción tecnológica supera con creces a nuestras capacidades de comprender, imaginar, sentir o asumir éticamente sus consecuencias**. Hemos perdido la capacidad de controlar y siquiera de representar simbólicamente nuestro desarrollo tecnológico. Por esa razón Eatherly no podía asumir lo que había hecho. La bomba atómica es algo tan atroz, representa un desfase prometeico tan grande, que nadie puede asumir la responsabilidad por algo así. Desborda toda categoría moral.

Según Anders, uno de los rasgos del desfase prometeico es que la tecnología moderna ha comenzado a progresar según su propia lógica interna, con total independencia de nuestras necesidades éticas y políticas. Aplicando esta idea a nuestro presente más inmediato, estamos teniendo el caso de que muchos de los responsables de las grandes tecnológicas de inteligencia artificial nos dicen que ésta es muy peligrosa, incluso un riesgo existencial para la humanidad, a la vez que mantienen una tenaz «carrera armamentística» por estar a la cabeza de su desarrollo. Todos pusimos una mueca irónica cuando Elon Musk firmaba la famosa carta en la que pedía una moratoria de seis meses en el avance de la IA, a la vez que se apresuraba a crear Grok. Da la impresión de que todo el mundo está muy asustado y nadie sabe qué va a pasar, a la vez que la IA avanza por sí sola a un ritmo cada vez más rápido, como si los seres humanos no pudiésemos hacer nada al respecto, como si una fuerza extrahumana, sobrenatural, estuviera impulsando el advenimiento de la lovecraftiana super inteligencia.

Yo, siempre he estado en contra de esta idea, que no es más que el clásico [*determinismo tecnológico*](https://es.wikipedia.org/wiki/Determinismo_tecnol%C3%B3gico). ==Creo que decir que la tecnología evoluciona con una lógica interna independiente del ser humano es una forma burda, tanto de exonerar a los responsables del desarrollo tecnológico de su responsabilidad, como de paralizar todo intento de detener cualquier tecnología perniciosa ¡Claro que el ser humano tiene que ver con el desarrollo tecnológico! ¡Y claro que el ser humano puede parar el desarrollo de tal o cual tecnología! Entonces, ¿por qué no lo hace?== En el caso de la IA hay dos razones fundamentales: primera, la pura y dura codicia, tanto por el rédito económico como por el reconocimiento social. Fue un tanto vergonzosa la visita de Sam Altman a una Europa en la que sus autoridades lo recibieron como un mesías, cuando más bien habría que haberle tirado bastante de las orejas. Y segunda, que no llegan a creerse que la IA sea tan peligrosa o que, en el caso de que los riesgos se disparen, creen que ellos mismos van a ser capaces de sortearlos. ==Es una estrategia política muy vieja crear un problema a la vez que te vendes como el único capaz de solucionarlo.==

Así que lo que hay que hacer es no creerse tanta patraña, plantar cara y pelear por un uso más ético y beneficioso de la IA. Detrás de toda tecnología hay personas con diferentes cuotas de responsabilidad a los que hay que pedir cuentas. Por ejemplo, estos días hemos visto una progresiva ruptura con la promesa de no utilizar la IA para uso militar por parte de las bigtechs. En este mismo mes de julio, OpenAI, Google, Anthropic y xAI, han firmado contratos de hasta doscientos millones de dólares cada uno, para fomentar las capacidades de IA en el Departamento de Defensa de Estados Unidos. Y sí, desgraciadamente para estos tipos, ser diseñador de armas que se usan para matar, aunque sean otros los que las usen (incluyendo agentes de IA autónomos), no te libra de tu parte de responsabilidad. Todos los físicos que participaron en el Proyecto Manhattan sabiendo lo que hacían tienen cuota de responsabilidad en Hiroshima.

Sin embargo, sí que creo que la tesis de Anders es cierta en un sentido. Si el control de la IA está en manos de media docena de empresas cuyo poder está por encima de las instituciones políticas y democráticas, sí que hemos perdido el control sobre ella. Quizá sea un rasgo del capitalismo tardío, postcapitalismo o como queramos llamarlo, el hecho de que **el desarrollo tecnológico se escape por completo a cualquier control institucional**. Creo que nunca antes se había atesorado tanto poder en unas pocas empresas, y eso es realmente peligroso porque, sin control político, solo nos queda confiar en que *sean* *buenos chicos* (recordemos el «Don’t be evil» como lema de Google). Es como en la monarquías medievales y absolutas. El pobre vasallo debía confiar en que su señor sería buena gente, porque no existía herramienta jurídica para echarlo si no lo era. Por eso la etiqueta de *tecnofeudalismo* de la que habla Varoufakis entre otros, no va demasiado desencaminada a la hora de designar en lo que se está convirtiendo nuestro sistema.

Pero además, siguiendo a Anders, si nuestra tecnología ha desbordado por completo nuestra capacidad de comprensión y, por tanto, de predicción, como parece estar pasando en el campo de la IA, no existe nadie competente para tratar con este tema. En palabras del propio Anders, «Lo que significa que, en este campo, nadie es competente y que **el apocalipsis está por tanto, por esencia, en manos de los incompetentes** ». Yo no soy tan apocalíptico con respecto a la IA, he escrito ya muchísimas veces contra esta idea; pero sí que creo que la IA va a traer, y está ya trayendo, muchísimos problemas y que los responsables no lo están haciendo, hasta ahora, demasiado bien. Y la causa no es que sean malvados, sino, simplemente, que no saben cómo hacerlo bien. Resumiendo: tenemos que confiar en que gente que no ha mostrado un comportamiento con unos altos estándares éticos, ahora sí lo muestre, y en que, además, sea competente en un campo en el que, por definición, no es posible… ¿Qué puede salir mal?

(Continuará)

Post data: la filosofía de Anders me parece muy en sintonía con las fastuosas obras de Benjamín Labatut *Un verdor terrible* y *Maniac*. Son dos novelas que recomiendo muchísimo. Y, por supuesto, con la *Oppenheimer* de Nolan.

---
